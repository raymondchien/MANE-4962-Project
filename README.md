# MANE-4962-Project
This is a modification to the code from paper [1] to accelerate the learning of PDEs from data when gradient information is available. This is an interesting problem because as shown in source [3] by using gradient information encoded in the cost function neural networks can be trained to be more accurate representations of the real function. 


# Sources

Li, Y. L., Rudner, T. G. J., & Wilson, A. G. (2023). A Study of Bayesian Neural Network Surrogates for Bayesian Optimization. http://arxiv.org/abs/2305.20028 [1] 
Lee, J., Bahri, Y., Novak, R., Schoenholz, S. S., Pennington, J., & Sohl-Dickstein, J. (2017). Deep Neural Networks as Gaussian Processes. http://arxiv.org/abs/1711.00165 [2]
Czarnecki, W. M., Osindero, S., Jaderberg, M., Swirszcz, G., & Pascanu, R. (n.d.). Sobolev Training for Neural Networks. [3] 
